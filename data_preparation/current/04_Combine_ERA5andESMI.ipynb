{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b40ae3b3-50bd-44e0-bea6-745b5369f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----********************-----\n",
    "\n",
    "# Created Time: 2024/10/09\n",
    "\n",
    "# Last updated: 2024/10/17\n",
    "\n",
    "# Author: Tara Liu, Yiyi He\n",
    "\n",
    "### Use Case\n",
    "\n",
    "# This notebook processes hourly ERA5 climate data and hourly ESMI voltage data and created merged datasets\n",
    "# 1. Combine hourly ERA5 climate data at all stations between 2013 to 2024\n",
    "# 2. Combine hourly voltage data at all stations\n",
    "# 3. Merge climate and voltage data (inner and outer)\n",
    "\n",
    "# -----********************-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a41fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c57246-2d28-495d-b44a-3d125b2ad04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine ERA5 climate data into one csv file\n",
    "input_dir = 'data/station_climate_by_year/'\n",
    "folders = os.listdir(input_dir)\n",
    "df_climate = pd.DataFrame()\n",
    "for folder in tqdm(folders):\n",
    "    if not folder.startswith('.'):\n",
    "        files = os.listdir(input_dir + '/' + folder)\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                df = pd.read_csv(input_dir + '/' + folder + '/' + file, index_col=0)\n",
    "                # add station_id, which is in the file name\n",
    "                df['station_id'] = file.split('_')[1]\n",
    "                df_climate = pd.concat([df_climate, df])\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        continue\n",
    "df_climate.drop(['From date', 'To date'], axis=1, inplace=True)\n",
    "df_climate['date'] = df_climate['date'].astype(str)\n",
    "df_climate['time'] = df_climate['time'].astype(str).apply(lambda x: x.zfill(4))\n",
    "df_climate['datetime'] = pd.to_datetime(df_climate['date'] + df_climate['time'], format='%Y%m%d%H%M')\n",
    "df_climate.set_index('datetime', inplace=True)\n",
    "df_climate.to_csv(\"df_climate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10f1db47-4e74-4369-853d-edc8aac80f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 536/536 [01:51<00:00,  4.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process hourly voltage data into one csv file\n",
    "input_dir = \"/Users/yiyi/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/Research/Energy_resilience/01_data/final_verification/india_processing/india_hourly\"\n",
    "files = os.listdir(input_dir)\n",
    "df_blackout = pd.DataFrame()\n",
    "\n",
    "for file in tqdm(files):\n",
    "    if file.endswith('.csv'):\n",
    "        df = pd.read_csv(input_dir + '/' + file)\n",
    "        df['station_id'] = file.split('_')[-1].split('.')[0]\n",
    "        df_blackout = pd.concat([df_blackout, df])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "df_blackout['hour'] = pd.to_datetime(df_blackout['hour'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_blackout.set_index('hour', inplace=True)\n",
    "# Save combined voltage data into one csv\n",
    "df_blackout.to_csv(\"df_blackout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbc4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read climate and voltage dataframes\n",
    "\n",
    "df_blackout_536 = pd.read_csv('/Users/yiyi/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/Research/Energy_resilience/01_data/2024_9_10_Tingyu/processed/df_blackout.csv')\n",
    "df_climate_538 = pd.read_csv('/Users/yiyi/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/Research/Energy_resilience/01_data/2024_9_10_Tingyu/processed/df_climate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd29c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids_out_bnds = [7, 143, 156, 159, 160, 261, 328, 353, 358, 450, 461, 472, 475, 476, 501, 506, 536, 546]\n",
    "df_blackout_518 = df_blackout_536[~df_blackout_536.station_id.isin(station_ids_out_bnds)]\n",
    "df_climate_520 = df_climate_538[~df_climate_538.station_id.isin(station_ids_out_bnds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5340449a-a841-4ad8-9504-dcdae0b6f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Voltage dataframe with Climate dataframe\n",
    "\n",
    "# First, reset the index to make the datetime index a regular column temporarily.\n",
    "df_climate_reset = df_climate_520.reset_index()\n",
    "df_blackout_reset = df_blackout_518.reset_index()\n",
    "\n",
    "# Rename column\n",
    "df_blackout_reset.rename(columns={\"hour\": \"datetime\"}, inplace=True)\n",
    "\n",
    "# Merge based on 'station_id' and 'datetime' (which was previously the index).\n",
    "df_merged_inner_518 = pd.merge(df_climate_reset, df_blackout_reset, on=['station_id', 'datetime'], how='inner')\n",
    "\n",
    "# Save outputs to csv files\n",
    "df_merged_inner_518.to_csv(\"df_merged_inner_518.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
