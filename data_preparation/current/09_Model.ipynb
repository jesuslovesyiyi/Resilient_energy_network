{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----********************-----\n",
    "\n",
    "# Created Time: 2024/12/09\n",
    "\n",
    "# Last updated: 2024/12/11\n",
    "\n",
    "# Author: Yiyi He, Tara Liu\n",
    "\n",
    "### Use Case\n",
    "\n",
    "# This notebook explores the application of autoregressive models\n",
    "# 1. \n",
    "\n",
    "# -----********************-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Stats\n",
    "from statsmodels.tsa.api import ARDL\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from statsmodels.tsa.ardl import ardl_select_order\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# Geo\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Processing\n",
    "from tqdm import tqdm\n",
    "import functools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def find_lag(df, maxlag):\n",
    "\n",
    "    time_start = pd.Timestamp.now()\n",
    "    \n",
    "    sel_res = ardl_select_order(\n",
    "        df['pct_blackout'],\n",
    "        exog=df[['t2m', 'wind_speed', 'tp']],\n",
    "        maxlag=maxlag,\n",
    "        ic='aic',\n",
    "        maxorder=maxlag,\n",
    "        causal=True,\n",
    "        trend='ct'\n",
    "        )\n",
    "    \n",
    "    time_selected = pd.Timestamp.now()\n",
    "    print(f'time elapsed for selecting order: {time_selected-time_start}')\n",
    "    \n",
    "    return sel_res.model.ardl_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>pct_blackout</th>\n",
       "      <th>wind_forest_cover</th>\n",
       "      <th>t2m</th>\n",
       "      <th>tp</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>station_id</th>\n",
       "      <th>climate_zone_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-11-17 17:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.09723</td>\n",
       "      <td>5.645638e-04</td>\n",
       "      <td>1.310930</td>\n",
       "      <td>495</td>\n",
       "      <td>Aw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-11-29 17:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293.04870</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.215274</td>\n",
       "      <td>495</td>\n",
       "      <td>Aw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-11-30 22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.83447</td>\n",
       "      <td>4.351137e-07</td>\n",
       "      <td>2.000125</td>\n",
       "      <td>495</td>\n",
       "      <td>Aw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  pct_blackout  wind_forest_cover        t2m  \\\n",
       "0  2014-11-17 17:00:00           0.0                0.0  295.09723   \n",
       "1  2014-11-29 17:00:00           0.0                0.0  293.04870   \n",
       "2  2014-11-30 22:00:00           0.0                0.0  289.83447   \n",
       "\n",
       "             tp  wind_speed  station_id climate_zone_code  \n",
       "0  5.645638e-04    1.310930         495                Aw  \n",
       "1  0.000000e+00    2.215274         495                Aw  \n",
       "2  4.351137e-07    2.000125         495                Aw  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load input dataframe\n",
    "df_518 = pd.read_csv(\"/Users/yiyi/Desktop/df_for_model.csv\")\n",
    "df_518.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_id = 100\n",
    "station_df = df_518[df_518['station_id'] == s_id]\n",
    "max_lag = 5\n",
    "sel_res = ardl_select_order(\n",
    "        station_df['pct_blackout'],\n",
    "        exog=station_df[['t2m', 'wind_speed', 'tp']],\n",
    "        maxlag=maxlag,\n",
    "        ic='aic',\n",
    "        maxorder=maxlag,\n",
    "        causal=True,\n",
    "        trend='ct'\n",
    "        )\n",
    "sel_res.model.ardl_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARDL find lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>pct_blackout</th>\n",
       "      <th>wind_forest_cover</th>\n",
       "      <th>t2m</th>\n",
       "      <th>tp</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>station_id</th>\n",
       "      <th>climate_zone_code</th>\n",
       "      <th>forest_perc_50kmbuffer</th>\n",
       "      <th>forest_perc_district</th>\n",
       "      <th>wind_forest_cover_50kmbu</th>\n",
       "      <th>wind_forest_cover_district</th>\n",
       "      <th>Am</th>\n",
       "      <th>Aw</th>\n",
       "      <th>BSh</th>\n",
       "      <th>Cw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-11-17 17:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.09723</td>\n",
       "      <td>5.645638e-04</td>\n",
       "      <td>1.310930</td>\n",
       "      <td>495</td>\n",
       "      <td>Aw</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-11-29 17:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293.04870</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.215274</td>\n",
       "      <td>495</td>\n",
       "      <td>Aw</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-11-30 22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.83447</td>\n",
       "      <td>4.351137e-07</td>\n",
       "      <td>2.000125</td>\n",
       "      <td>495</td>\n",
       "      <td>Aw</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  pct_blackout  wind_forest_cover        t2m  \\\n",
       "0  2014-11-17 17:00:00           0.0                0.0  295.09723   \n",
       "1  2014-11-29 17:00:00           0.0                0.0  293.04870   \n",
       "2  2014-11-30 22:00:00           0.0                0.0  289.83447   \n",
       "\n",
       "             tp  wind_speed  station_id climate_zone_code  \\\n",
       "0  5.645638e-04    1.310930         495                Aw   \n",
       "1  0.000000e+00    2.215274         495                Aw   \n",
       "2  4.351137e-07    2.000125         495                Aw   \n",
       "\n",
       "   forest_perc_50kmbuffer  forest_perc_district  wind_forest_cover_50kmbu  \\\n",
       "0                  0.0006                0.0006                  0.000787   \n",
       "1                  0.0006                0.0006                  0.001329   \n",
       "2                  0.0006                0.0006                  0.001200   \n",
       "\n",
       "   wind_forest_cover_district  Am  Aw  BSh  Cw  \n",
       "0                    0.000787   0   1    0   0  \n",
       "1                    0.001329   0   1    0   0  \n",
       "2                    0.001200   0   1    0   0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load input dataframe\n",
    "df_518 = pd.read_csv(\"/Users/yiyi/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/Research/Energy_resilience/01_data/2024_9_10_Tingyu/processed/station_518_forest_perc_50kmBu_district_climate_dummy_df.csv\",\n",
    "                     index_col=0)\n",
    "df_518.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of unique station ids\n",
    "station_id_lst = list(set(df_518.station_id.unique()))\n",
    "# Initiate an empty dictionary\n",
    "station_id_lag_dic = {}\n",
    "# Set max lag\n",
    "maxlag = 24\n",
    "# Iterate through all stations\n",
    "for s_id in tqdm(station_id_lst):\n",
    "    # Subset station data\n",
    "    station_df = df_518[df_518['station_id'] == s_id].sort_values(by='datetime')\n",
    "    # Find optimum lag and store station id with optimum lag in dictionary\n",
    "    sel_res = ardl_select_order(\n",
    "        station_df['pct_blackout'],\n",
    "        exog=station_df[['t2m', 'wind_speed', 'tp']],\n",
    "        maxlag=maxlag,\n",
    "        ic='bic',\n",
    "        maxorder=maxlag,\n",
    "        causal=True,\n",
    "        trend='ct'\n",
    "        )\n",
    "    # optimum lag values for endogenous variables\n",
    "    endo_res_lst = list(sel_res.aic.values[0][1].values())\n",
    "    # insert the optimum lag value for exdogenous variable\n",
    "    endo_res_lst.insert(0, sel_res.aic.values[0][0])\n",
    "    # store station id and optimum lag values in dictionary\n",
    "    station_id_lag_dic[s_id] = endo_res_lst # key: station id, value:[pct_blackout_lag, t2m_lag, wind_speed_lag, tp_lag]\n",
    "\n",
    "station_id_lag_dic_copy = station_id_lag_dic\n",
    "station_id_lag_df = pd.DataFrame.from_dict(station_id_lag_dic_copy, orient='index')\n",
    "\n",
    "station_id_optimum_lag_bic_df = station_id_lag_df.reset_index().rename(columns={\n",
    "                                                          'index': 'station_id',\n",
    "                                                          0: 'pct_blackout_lag',\n",
    "                                                          1: 't2m_lag',\n",
    "                                                          2: 'wind_speed_lag',\n",
    "                                                          3: 'tp_lag'\n",
    "                                                          })\n",
    "station_id_optimum_lag_bic_df.to_csv('/Users/yiyi/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/Research/Energy_resilience/01_data/2024_9_10_Tingyu/processed/station_516_ARDL_optimum_lag_bic_max24_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataframe\n",
    "station_daily_agg = pd.read_csv('/Users/yiyi/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/Research/Energy_resilience/01_data/2024_9_10_Tingyu/processed/station_518_weather_daily_agg.csv',\n",
    "                                index_col=0)\n",
    "station_daily_agg.head(3)\n",
    "\n",
    "# Set max lag\n",
    "maxlag = 5\n",
    "# Target\n",
    "target = \"blackout_minutes\"\n",
    "predictors_lst = [\n",
    "                't2m_min',\n",
    "                't2m_median',\n",
    "                't2m_max',\n",
    "                'wind_speed_median',\n",
    "                'wind_speed_max',\n",
    "                'tp_median',\n",
    "                'tp_max']\n",
    "\n",
    "# Create a list of unique station ids\n",
    "station_id_lst = list(set(station_daily_agg.station_id.unique()))\n",
    "\n",
    "# Identify stations with fewer than 90 days worth of data\n",
    "groupby_station = station_daily_agg.groupby('station_id')\n",
    "fewer90_station_ids = groupby_station.count()[groupby_station.count().date<92].index.values # np array\n",
    "\n",
    "# Initiate an empty dictionary\n",
    "station_id_daily_lag_bic = {}\n",
    "\n",
    "# Iterate through all stations\n",
    "for s_id in tqdm(station_id_lst):\n",
    "    if s_id in fewer90_station_ids:\n",
    "        continue\n",
    "    else:\n",
    "        # Subset station data\n",
    "        station_df = station_daily_agg[station_daily_agg['station_id'] == s_id].sort_values(by='date')\n",
    "        # Find optimum lag and store station id with optimum lag in dictionary\n",
    "        sel_res = ardl_select_order(\n",
    "            station_df[target],\n",
    "            exog=station_df[predictors_lst],\n",
    "            maxlag=maxlag,\n",
    "            ic='bic',\n",
    "            maxorder=maxlag,\n",
    "            causal=True,\n",
    "            trend='ct'\n",
    "            )\n",
    "        # optimum lag values for endogenous variables\n",
    "        endo_res_lst = list(sel_res.bic.values[0][1].values())\n",
    "        # insert the optimum lag value for exdogenous variable\n",
    "        endo_res_lst.insert(0, sel_res.bic.values[0][0])\n",
    "        # store station id and optimum lag values in dictionary\n",
    "        station_id_daily_lag_bic[s_id] = endo_res_lst # key: station id, value:[pct_blackout_lag, t2m_lag, wind_speed_lag, tp_lag]\n",
    "\n",
    "station_id_daily_lag_bic_df = pd.DataFrame.from_dict(station_id_lag_dic_copy, orient='index')\n",
    "\n",
    "station_id_optimum_lag_bic_df = station_id_lag_df.reset_index().rename(columns={\n",
    "                                                                       'index': 'station_id',\n",
    "                                                                    0: 'blackout_m_lag',\n",
    "                                                                    1: 't2m_min_lag',\n",
    "                                                                    2: 't2m_median_lag',\n",
    "                                                                    3: 't2m_max_lag',\n",
    "                                                                    4: 'wind_speed_median_lag',\n",
    "                                                                    5: 'wind_speed_max_lag',\n",
    "                                                                    6: 'tp_median_lag',\n",
    "                                                                    7: 'tp_max_lag'\n",
    "                                                                    })\n",
    "station_id_optimum_lag_bic_df.to_csv('/Users/yiyi/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology(2)/Research/Energy_resilience/01_data/2024_9_10_Tingyu/processed/station_id_daily_lag5_bic_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granger Causality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [2:03:30<00:00, 14.36s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Create a list of unique station ids\n",
    "station_id_lst = list(set(df_518.station_id.unique()))\n",
    "# Set max lag\n",
    "maxlag = 72\n",
    "# Target\n",
    "target = \"pct_blackout\"\n",
    "# Predictor\n",
    "predictor = \"tp\"\n",
    "\n",
    "# Initiate an empty dictionary\n",
    "station_id_tp_gc_max72_dic = {}\n",
    "\n",
    "# List of stations visited\n",
    "# existing_keys = station_id_t2m_gc_max72_dic.keys()\n",
    "# Iterate through all stations\n",
    "for s_id in tqdm(station_id_lst):\n",
    "    if s_id == 518 or s_id == 563:\n",
    "        continue \n",
    "    else:\n",
    "        # Subset station data\n",
    "        station_df = df_518[df_518['station_id'] == s_id].sort_values(by='datetime')\n",
    "        test_result = grangercausalitytests(\n",
    "            station_df[[target, predictor]], maxlag=maxlag, addconst=True, verbose=False)\n",
    "        F_test_p_values = [round(test_result[i+1][0]['ssr_ftest'][1],4) for i in range(maxlag)]\n",
    "        Chi_squared_p_values = [round(test_result[i+1][0]['ssr_chi2test'][1],4) for i in range(maxlag)]\n",
    "        p_values_min = np.min(F_test_p_values+Chi_squared_p_values)\n",
    "        # Key: station id, Value: list of 1. minimum F/Chi p values 2. F-test p values for all lags 3. Chi-square test p-values for all lags\n",
    "        station_id_tp_gc_max72_dic[s_id] = [p_values_min, F_test_p_values, Chi_squared_p_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store granger causality results (p values for 2 tests, minimum p-value) for one predictor in dataframe\n",
    "station_id_tp_gc_max72_df = pd.DataFrame.from_dict(station_id_tp_gc_max72_dic, orient='index').reset_index()\n",
    "station_id_tp_gc_max72_df.rename(columns={\n",
    "    'index':'station_id',\n",
    "    0:'tp_p-value_min',\n",
    "    1:'tp_f_p-value',\n",
    "    2:'tp_Chi_p-value'\n",
    "}, inplace=True)\n",
    "# Join dataframes\n",
    "dfs = [station_id_t2m_gc_max72_df, station_id_windspeed_gc_max72_df, station_id_tp_gc_max72_df]\n",
    "df_joined= ft.reduce(lambda left, right: pd.merge(left, right, on='station_id'), dfs)\n",
    "# df_joined.to_csv('/Users/yiyi/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/Research/Energy_resilience/01_data/2024_9_10_Tingyu/processed/station_514_gc_max72_pvalue_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the results of granger causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pvalues_max72 = df_joined[['station_id', 't2m_p-value_min', 'windspeed_p-value_min', 'tp_p-value_min']]\n",
    "station_daily_gc_max30_df_pmin_binarydf_pvalues_max72_binary = df_pvalues_max72.set_index('station_id')<0.05\n",
    "summary = pd.DataFrame({\n",
    "    'True': df_pvalues_max72_binary.apply(lambda x: (x == True).sum()),\n",
    "    'False': df_pvalues_max72_binary.apply(lambda x: (x == False).sum())\n",
    "    })\n",
    "summary\n",
    "# df_pvalues_max72.to_csv('/Users/yiyi/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/Research/Energy_resilience/01_data/2024_9_10_Tingyu/processed/station_514_gc_max72_pvalue_reduced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 84/516 [00:19<01:34,  4.59it/s]"
     ]
    }
   ],
   "source": [
    "# Read in dataframe\n",
    "station_daily_agg = pd.read_csv('/Users/yiyi/Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/Research/Energy_resilience/01_data/2024_9_10_Tingyu/processed/station_518_weather_daily_agg.csv',\n",
    "                                index_col=0)\n",
    "station_daily_agg.head(3)\n",
    "\n",
    "# Output folder path\n",
    "out_folder = Path.home()\\\n",
    "/\"Library/CloudStorage/\"\\\n",
    "/\"OneDrive-GeorgiaInstituteofTechnology/\"\\\n",
    "/\"Research/Energy_resilience/01_data/\"\\\n",
    "/\"2024_9_10_Tingyu/processed/daily_maxlag30_dfs/\"\n",
    "\n",
    "# Identify stations with fewer than 90 days worth of data\n",
    "groupby_station = station_daily_agg.groupby('station_id')\n",
    "fewer90_station_ids = groupby_station.count()[groupby_station.count().date<92].index.values\n",
    "\n",
    "# Create a list of unique station ids\n",
    "station_id_lst = list(set(station_daily_agg.station_id.unique()))\n",
    "\n",
    "# Set max lag\n",
    "maxlag = 30\n",
    "# Target\n",
    "target = \"blackout_minutes\"\n",
    "# Predictors\n",
    "weather_variables = ['t2m', 'wind_speed', 'tp']\n",
    "aggregations = ['min', 'median', 'mean', 'max']\n",
    "predictor_lst = [w + \"_\" + a for w in weather_variables for a in aggregations]\n",
    "\n",
    "for predictor in predictor_lst:\n",
    "    # Initiate an empty dictionary\n",
    "    station_dic = {}\n",
    "\n",
    "    for s_id in tqdm(station_id_lst):\n",
    "        if s_id in fewer90_station_ids:\n",
    "            continue \n",
    "        else:\n",
    "            # Subset station data\n",
    "            station_df = station_daily_agg[station_daily_agg['station_id'] == s_id].sort_values(by='date')\n",
    "            try:\n",
    "                test_result = grangercausalitytests(\n",
    "                    station_df[[target, predictor]], maxlag=maxlag, addconst=True, verbose=False)\n",
    "                F_test_p_values = [round(test_result[i+1][0]['ssr_ftest'][1],4) for i in range(maxlag)]\n",
    "                Chi_squared_p_values = [round(test_result[i+1][0]['ssr_chi2test'][1],4) for i in range(maxlag)]\n",
    "                p_values_min = np.min(F_test_p_values+Chi_squared_p_values)\n",
    "                # Key: station id, Value: list of 1. minimum F/Chi p values 2. F-test p values for all lags 3. Chi-square test p-values for all lags\n",
    "                station_dic[s_id] = [p_values_min, F_test_p_values, Chi_squared_p_values]\n",
    "            except:\n",
    "                station_dic[s_id] = [np.nan, np.nan, np.nan]\n",
    "\n",
    "    station_gc_max30_df = pd.DataFrame.from_dict(station_dic, orient='index').reset_index()\n",
    "    station_gc_max30_df.rename(columns={\n",
    "    'index':'station_id',\n",
    "    0:f'{predictor}_p-value_min',\n",
    "    1:f'{predictor}_f_p-value',\n",
    "    2:f'{predictor}_Chi_p-value'\n",
    "    }, inplace=True)\n",
    "    station_gc_max30_df.to_csv(Path(out_folder)/f'station_gc_max30_{predictor}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = Path.home()\\\n",
    "/\"Library/CloudStorage/\"\\\n",
    "/\"OneDrive-GeorgiaInstituteofTechnology/\"\\\n",
    "/\"Research/Energy_resilience/01_data/\"\\\n",
    "/\"2024_9_10_Tingyu/processed/daily_maxlag30_dfs/\"\n",
    "\n",
    "weather_variables = ['t2m', 'wind_speed', 'tp']\n",
    "aggregations = ['min', 'median', 'mean', 'max']\n",
    "pmin_col_names = [w + \"_\" + a + \"_p-value_min\"\\\n",
    "                  for w in weather_variables\\\n",
    "                  for a in aggregations]\n",
    "\n",
    "station_daily_gc_max30_df_lst = []\n",
    "for file in os.listdir(out_folder):\n",
    "    if file[-3:] == 'csv':\n",
    "        df = pd.read_csv(os.path.join(out_folder,file),\n",
    "                         index_col=0)\n",
    "        station_daily_gc_max30_df_lst.append(df)\n",
    "station_daily_gc_max30_df_joined= ft.reduce(lambda left, right: pd.merge(left, right, on='station_id'),\n",
    "                     station_daily_gc_max30_df_lst)\n",
    "\n",
    "station_daily_gc_max30_df_pmin = station_daily_gc_max30_df_joined[['station_id']+pmin_col_names]\n",
    "station_daily_gc_max30_df_pmin_binary = station_daily_gc_max30_df_pmin.set_index('station_id')<0.05\n",
    "summary = pd.DataFrame({\n",
    "    'True': station_daily_gc_max30_df_pmin_binary.apply(lambda x: (x == True).sum()),\n",
    "    'False': station_daily_gc_max30_df_pmin_binary.apply(lambda x: (x == False).sum())\n",
    "    })\n",
    "summary.to_csv(Path(out_folder)/'station_daily_gc_max30_p_value_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.machinelearningplus.com/time-series/granger-causality-test-in-python/\n",
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n",
    "    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n",
    "    The rows are the response variable, columns are predictors. The values in the table \n",
    "    are the P-Values. P-Values lesser than the significance level (0.05), implies \n",
    "    the Null Hypothesis that the coefficients of the corresponding past values is \n",
    "    zero, that is, the X does not cause Y can be rejected.\n",
    "\n",
    "    data      : pandas dataframe containing the time series variables\n",
    "    variables : list containing names of the time series variables.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_blackout_x</th>\n",
       "      <th>t2m_x</th>\n",
       "      <th>wind_speed_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pct_blackout_y</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2m_y</th>\n",
       "      <td>0.0472</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_speed_y</th>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pct_blackout_x   t2m_x  wind_speed_x\n",
       "pct_blackout_y          1.0000  0.0271        0.2261\n",
       "t2m_y                   0.0472  1.0000        0.0000\n",
       "wind_speed_y            0.0023  0.0000        1.0000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grangers_causation_matrix(station_df, ['pct_blackout', 't2m', 'wind_speed'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
