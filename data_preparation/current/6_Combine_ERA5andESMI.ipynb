{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_climate_data(input_dir):\n",
    "\tfolders = os.listdir(input_dir)\n",
    "\tdf_climate = pd.DataFrame()\n",
    "\n",
    "\tfor folder in folders:\n",
    "\t\tfiles = os.listdir(input_dir + '/' + folder)\n",
    "\n",
    "\t\tfor file in files:\n",
    "\t\t\tdf = pd.read_csv(input_dir + '/' + folder + '/' + file)\n",
    "\t\t\t# add station_id which is in the file name\n",
    "\t\t\tdf['station_id'] = file.split('_')[0]\n",
    "\t\t\tdf_climate = pd.concat([df_climate, df])\n",
    "\n",
    "\tdf_climate.drop(['From date', 'To date'], axis=1, inplace=True)\n",
    "\tdf_climate['date'] = df_climate['date'].astype(str)\n",
    "\tdf_climate['time'] = df_climate['time'].astype(str).apply(lambda x: x.zfill(4))\n",
    "\tdf_climate['datetime'] = pd.to_datetime(df_climate['date'] + df_climate['time'], format='%Y%m%d%H%M')\n",
    "\tdf_climate.set_index('datetime', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\tprint('Finished reading data...info below:')\n",
    "\tprint(df_climate.info())\n",
    "\n",
    "\tprint('index:', df_climate.index)\n",
    "\treturn df_climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_blackout_data(input_dir):\n",
    "\tfiles = os.listdir(input_dir)\n",
    "\tprint(files)\n",
    "\tdf_blackout = pd.DataFrame()\n",
    "\n",
    "\tfor file in files:\n",
    "\t\tdf = pd.read_csv(input_dir + '/' + file)\n",
    "\t\tdf['station_id'] = file.split('_')[-1].split('.')[0]\n",
    "\t\tdf_blackout = pd.concat([df_blackout, df])\n",
    "\n",
    "\tdf_blackout['hour'] = pd.to_datetime(\n",
    "\t\tdf_blackout['hour'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\tdf_blackout.set_index('hour', inplace=True)\n",
    "\tprint('Finished reading data...info below:')\n",
    "\tprint(df_blackout.info())\n",
    "\tprint('index:', df_blackout.index)\n",
    "\treturn df_blackout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_climate \u001b[38;5;241m=\u001b[39m \u001b[43mread_climate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/station_climate_by_year\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print columns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_climate\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m, in \u001b[0;36mread_climate_data\u001b[0;34m(input_dir)\u001b[0m\n\u001b[1;32m      6\u001b[0m files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(input_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m folder)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m----> 9\u001b[0m \tdf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \t\u001b[38;5;66;03m# add station_id which is in the file name\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \tdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstation_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/india0/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/india0/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/india0/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/india0/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/india0/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte"
     ]
    }
   ],
   "source": [
    "df_climate = read_climate_data('data/station_climate_by_year')\n",
    "\n",
    "# print columns\n",
    "print(df_climate.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hourly_station_217.csv', 'hourly_station_563.csv', 'hourly_station_445.csv']\n",
      "Finished reading data...info below:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 34200 entries, 2014-11-24 13:00:00 to 2018-10-01 08:00:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   pct_blackout  34200 non-null  float64\n",
      " 1   station_id    34200 non-null  object \n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 801.6+ KB\n",
      "None\n",
      "index: DatetimeIndex(['2014-11-24 13:00:00', '2014-11-24 14:00:00',\n",
      "               '2014-11-24 15:00:00', '2014-11-24 16:00:00',\n",
      "               '2014-11-24 17:00:00', '2014-11-24 18:00:00',\n",
      "               '2014-11-24 19:00:00', '2014-11-24 20:00:00',\n",
      "               '2014-11-24 21:00:00', '2014-11-24 22:00:00',\n",
      "               ...\n",
      "               '2018-08-22 22:00:00', '2018-08-22 23:00:00',\n",
      "               '2018-08-23 00:00:00', '2018-08-23 01:00:00',\n",
      "               '2018-08-23 02:00:00', '2018-08-23 03:00:00',\n",
      "               '2018-08-23 04:00:00', '2018-08-23 05:00:00',\n",
      "               '2018-08-23 06:00:00', '2018-10-01 08:00:00'],\n",
      "              dtype='datetime64[ns]', name='hour', length=34200, freq=None)\n",
      "columns: Index(['pct_blackout', 'station_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_blackout = read_blackout_data('../../data/india_hourly')\n",
    "\n",
    "# print(df_blackout['station_id'].unique())\n",
    "# print columns name\n",
    "print('columns:',df_blackout.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2013-11-15 10:00:00', '2013-12-09 02:00:00',\n",
      "               '2013-07-14 04:00:00', '2013-11-13 18:00:00',\n",
      "               '2013-09-14 03:00:00', '2013-07-10 14:00:00',\n",
      "               '2013-10-30 12:00:00', '2013-11-11 00:00:00',\n",
      "               '2013-08-09 09:00:00', '2013-11-17 08:00:00',\n",
      "               ...\n",
      "               '2014-06-26 23:00:00', '2014-11-27 18:00:00',\n",
      "               '2014-02-07 16:00:00', '2014-08-01 11:00:00',\n",
      "               '2014-04-25 23:00:00', '2014-01-25 04:00:00',\n",
      "               '2014-11-19 18:00:00', '2014-09-20 03:00:00',\n",
      "               '2014-06-18 23:00:00', '2014-03-18 04:00:00'],\n",
      "              dtype='datetime64[ns]', name='datetime', length=13536, freq=None)\n",
      "DatetimeIndex(['2014-11-24 13:00:00', '2014-11-24 14:00:00',\n",
      "               '2014-11-24 15:00:00', '2014-11-24 16:00:00',\n",
      "               '2014-11-24 17:00:00', '2014-11-24 18:00:00',\n",
      "               '2014-11-24 19:00:00', '2014-11-24 20:00:00',\n",
      "               '2014-11-24 21:00:00', '2014-11-24 22:00:00',\n",
      "               ...\n",
      "               '2018-08-22 22:00:00', '2018-08-22 23:00:00',\n",
      "               '2018-08-23 00:00:00', '2018-08-23 01:00:00',\n",
      "               '2018-08-23 02:00:00', '2018-08-23 03:00:00',\n",
      "               '2018-08-23 04:00:00', '2018-08-23 05:00:00',\n",
      "               '2018-08-23 06:00:00', '2018-10-01 08:00:00'],\n",
      "              dtype='datetime64[ns]', name='hour', length=34200, freq=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_climate.index)\n",
    "print(df_blackout.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Location name', 'ESMI_ID', 'District', 'State',\n",
      "       'Category', 'Connection Type', 'Lat', 'Lon', 't2m', 'u10', 'v10', 'tp',\n",
      "       'date', 'time', 'station_id_climate', 'pct_blackout',\n",
      "       'station_id_blackout'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# merge df_climate, df_blackout with datetime and station_id: \n",
    "# in df_climate, the merge index is datetime and station_id\n",
    "# in df_blackout, index is hour and station_id\n",
    "\n",
    "df = pd.merge(df_climate, df_blackout, left_index=True, right_index=True, how='inner', suffixes=('_climate', '_blackout'))\n",
    "\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 655 entries, 2014-11-24 13:00:00 to 2014-12-31 23:00:00\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           655 non-null    int64  \n",
      " 1   Location name        655 non-null    object \n",
      " 2   ESMI_ID              0 non-null      float64\n",
      " 3   District             655 non-null    object \n",
      " 4   State                655 non-null    object \n",
      " 5   Category             655 non-null    object \n",
      " 6   Connection Type      655 non-null    object \n",
      " 7   Lat                  655 non-null    float64\n",
      " 8   Lon                  655 non-null    float64\n",
      " 9   t2m                  655 non-null    float64\n",
      " 10  u10                  655 non-null    float64\n",
      " 11  v10                  655 non-null    float64\n",
      " 12  tp                   655 non-null    float64\n",
      " 13  date                 655 non-null    object \n",
      " 14  time                 655 non-null    object \n",
      " 15  station_id_climate   655 non-null    object \n",
      " 16  pct_blackout         655 non-null    float64\n",
      " 17  station_id_blackout  655 non-null    object \n",
      "dtypes: float64(8), int64(1), object(9)\n",
      "memory usage: 97.2+ KB\n",
      "None\n",
      "                     Unnamed: 0  Location name  ESMI_ID District  \\\n",
      "2014-11-24 13:00:00        6327  Sikandarabad       NaN  Sitapur   \n",
      "2014-11-24 14:00:00        4457  Sikandarabad       NaN  Sitapur   \n",
      "2014-11-24 15:00:00        3873  Sikandarabad       NaN  Sitapur   \n",
      "2014-11-24 16:00:00        3163  Sikandarabad       NaN  Sitapur   \n",
      "2014-11-24 17:00:00        6043  Sikandarabad       NaN  Sitapur   \n",
      "\n",
      "                             State        Category Connection Type        Lat  \\\n",
      "2014-11-24 13:00:00  Uttar Pradesh  Gram Panchayat        Domestic  27.954139   \n",
      "2014-11-24 14:00:00  Uttar Pradesh  Gram Panchayat        Domestic  27.954139   \n",
      "2014-11-24 15:00:00  Uttar Pradesh  Gram Panchayat        Domestic  27.954139   \n",
      "2014-11-24 16:00:00  Uttar Pradesh  Gram Panchayat        Domestic  27.954139   \n",
      "2014-11-24 17:00:00  Uttar Pradesh  Gram Panchayat        Domestic  27.954139   \n",
      "\n",
      "                           Lon        t2m       u10       v10            tp  \\\n",
      "2014-11-24 13:00:00  80.491162  292.49493  2.014306 -1.304936  8.553265e-07   \n",
      "2014-11-24 14:00:00  80.491162  290.62530  1.939066 -1.267732  8.553265e-07   \n",
      "2014-11-24 15:00:00  80.491162  289.07650  1.993549 -1.040938  8.553265e-07   \n",
      "2014-11-24 16:00:00  80.491162  287.76422  2.078859 -0.714382  1.722779e-06   \n",
      "2014-11-24 17:00:00  80.491162  286.74090  2.225251 -0.380365  1.710557e-06   \n",
      "\n",
      "                         date  time station_id_climate  pct_blackout  \\\n",
      "2014-11-24 13:00:00  20141124  1300            station      0.000000   \n",
      "2014-11-24 14:00:00  20141124  1400            station      0.000000   \n",
      "2014-11-24 15:00:00  20141124  1500            station      0.066667   \n",
      "2014-11-24 16:00:00  20141124  1600            station      0.066667   \n",
      "2014-11-24 17:00:00  20141124  1700            station      0.016667   \n",
      "\n",
      "                    station_id_blackout  \n",
      "2014-11-24 13:00:00                 217  \n",
      "2014-11-24 14:00:00                 217  \n",
      "2014-11-24 15:00:00                 217  \n",
      "2014-11-24 16:00:00                 217  \n",
      "2014-11-24 17:00:00                 217  \n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv('../../data/merged_data.csv')\n",
    "\n",
    "# fix: id seems not the same, need to check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2m           292.49493\n",
      "u10            2.014306\n",
      "v10           -1.304936\n",
      "station_id          217\n",
      "Name: 2014-11-24 13:00:00, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# select the t2m, u10, v10, and station_id for datetime 2014-11-24 13:00:00, station Sikandarabad\n",
    "\n",
    "print(df.loc['2014-11-24 13:00:00', ['t2m', 'u10', 'v10', 'station_id']])\n",
    "\n",
    "# select the t2m, u10, v10, and station_id for datetime 2014-11-24 13:00:00, station Sikandarabad\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "india0",
   "language": "python",
   "name": "india0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
