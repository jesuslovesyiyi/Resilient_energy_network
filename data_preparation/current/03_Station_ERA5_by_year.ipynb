{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "41c0c967-da4d-411f-96e9-d2247d4cd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----********************-----\n",
    "\n",
    "# Created Time: 2024/09/23\n",
    "\n",
    "# Author: Yiyi He\n",
    "\n",
    "### Use Case\n",
    "\n",
    "# This notebook processes climate data at stations into the follow format:\n",
    "# For a given year and station, 4 climate variables will be organized in one csv file\n",
    "\n",
    "### Climate variables:\n",
    "# t2m: Temperature of air at 2m above the surface of land, sea or in-land waters.\n",
    "# u10: Eastward component of the 10m wind.\n",
    "# v10: Northward component of the 10m wind.\n",
    "# tp: Total precipitation. Accumulated liquid and frozen water, including rain and snow, that falls to the Earth's surface.\n",
    "\n",
    "# -----********************-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8322bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf1a77-40eb-448a-ba27-ba2d321c225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = 'station_climate_by_year'\n",
    "for year in range(2013, 2025):\n",
    "    os.makedirs(os.path.join(output_dir, str(year)), exist_ok=True)  # exist_ok=True avoids error if the folder already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0ee5e40b-3ab5-451c-af2c-878804b5a8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am working on year 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8760/8760 [47:16<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am working on year 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6093/6093 [21:08<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am working on year 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8760/8760 [45:18<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am working on year 2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8760/8760 [45:45<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am working on year 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8760/8760 [45:53<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am working on year 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8760/8760 [43:52<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am working on year 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8784/8784 [43:58<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am working on year 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8760/8760 [44:04<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am working on year 2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8784/8784 [44:45<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Input directory\n",
    "input_dir = 'station_by_datetime_csv'\n",
    "# Output directory\n",
    "output_dir = 'station_climate_by_year'\n",
    "# Initiate column names for the output dataframe\n",
    "column_names = ['Location name', 'ESMI_ID', 'From date', 'To date',\n",
    "       'District', 'State', 'Category', 'Connection Type', 'Lat', 'Lon', 't2m',\n",
    "       'u10', 'v10', 'tp', 'date', 'time']\n",
    "\n",
    "# Iterate through years\n",
    "for year_folder in os.listdir(input_dir):\n",
    "    if year_folder in [str(year) for year in range(2016, 2025)]:\n",
    "        year = int(year_folder)\n",
    "        print(f'I am working on year {year}')\n",
    "        # Initiate a dictionary that will store hourly climate data for each station\n",
    "        station_climate = {}\n",
    "        # Iterate through hours in a year\n",
    "        for hour_csv in tqdm(os.listdir(os.path.join(input_dir, year_folder))):\n",
    "            if hour_csv.endswith('.csv'): # making sure it is a csv file\n",
    "                # Read csv as pandas dataframe\n",
    "                df_raw = pd.read_csv(os.path.join(input_dir, year_folder, hour_csv), index_col=0)\n",
    "                # Extract data from each row and populate the station_climate dictionary. Key: Station id; Value: nd array of hourly climate variables\n",
    "                for row in range(df_raw.shape[0]):\n",
    "                    # Extract station id\n",
    "                    station_id = df_raw.iloc[row].values[0]\n",
    "                    # Check if the station ID exists in the dictionary as key\n",
    "                    if station_id in station_climate:\n",
    "                        existing_climate_array = station_climate[station_id]\n",
    "                        station_climate[station_id] = np.concatenate(\n",
    "                            (\n",
    "                                existing_climate_array,\n",
    "                            df_raw.iloc[row].values[1:].reshape(1, 16)\n",
    "                            ),\n",
    "                            axis=0\n",
    "                        )\n",
    "                    else:\n",
    "                        station_climate[station_id] = df_raw.iloc[row].values[1:].reshape(1, 16)\n",
    "\n",
    "        for station in station_climate.keys():\n",
    "            station_year_df = pd.DataFrame(station_climate[station], columns=column_names)\n",
    "            station_year_df.to_csv(os.path.join(output_dir, str(year), f'station_{station}_{year}.csv'))\n",
    "    else:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "india0",
   "language": "python",
   "name": "india0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
