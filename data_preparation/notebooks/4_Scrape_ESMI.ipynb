{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def date2query(date):\n",
    "    return urllib.parse.quote(date.strftime('%d/%m/%Y'), safe='')\n",
    "\n",
    "# Robust request function that automatically retries\n",
    "def retry_request(url, session, total=4, status_forcelist=[429, 500, 502, 503, 504], **kwargs):\n",
    "    for _ in range(total):\n",
    "        try:\n",
    "            response = session.get(url, **kwargs)\n",
    "            if response.status_code in status_forcelist:\n",
    "                continue\n",
    "            return response\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "session = requests.Session()\n",
    "LOGIN_URL = 'http://www.watchyourpower.org/admin/'\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Mobile Safari/537.36'\n",
    "}\n",
    "\n",
    "page_text = retry_request(url=LOGIN_URL, session=session, headers=HEADERS)\n",
    "img_url = 'http://www.watchyourpower.org/captcha.php'\n",
    "img_data = retry_request(url=img_url, session=session, headers=HEADERS).content\n",
    "\n",
    "with open('./captcha.jpg', 'wb') as fp:\n",
    "    fp.write(img_data)\n",
    "\n",
    "image = mpimg.imread(\"./captcha.jpg\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "img_code = input('Enter captchaï¼š')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "USERNAME = 'junrentschler'\n",
    "PASSWORD = 'jun@2018'\n",
    "data = {'username': USERNAME, 'password': PASSWORD, 'code': img_code, 'login': 'Login'}\n",
    "\n",
    "index = session.post(url=LOGIN_URL, headers=HEADERS, data=data)\n",
    "print(index)\n",
    "\n",
    "DETAIL_URL = 'http://www.watchyourpower.org/reports.php?category_id=3&location_id=119&from_date=13%2F01%2F2017&to_date=13%2F02%2F2017'\n",
    "detail_text = retry_request(url=DETAIL_URL, session=session, headers=HEADERS).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if detail_text.find('Welcome') == -1:\n",
    "    exit()\n",
    "\n",
    "INDIA_SCRAPE_DIR = 'india_esmi'\n",
    "API_URL = 'http://www.watchyourpower.org/reports.php?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous scraping log found:\n",
      "Last read: 09/24/2024\n",
      "\n",
      "Alipur_Cachar+Cachar+Assam\n",
      "No valid data range for station 887, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ameerpeth-Hyderabad+Hyderabad+Andhra_Pradesh_Telangana\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 11/17/2023 to 12/17/2023 for station 171: : 351it [00:35,  9.86it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 479760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrit_Nagar_Hazaribagh+Hazaribagh+Jharkhand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 12/19/2023 to 12/26/2023 for station 905: : 360it [00:35, 10.00it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 517800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aundh-Pune+Pune+Maharashtra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 12/19/2023 to 12/26/2023 for station 130: : 360it [00:39,  9.10it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 517800\n",
      "Banjara_hills_Hyderabad+Hyderabad+Telangana\n",
      "No valid data range for station 673, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Besant_Nagar_Chennai+Kancheepuram+Tamil_Nadu\n",
      "Total entries: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/311 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhopoli-Palghar+Palghar+Maharashtra\n",
      "Total entries: 0\n",
      "Bhurkunda_Ramgarh+Bhurkunda+Jharkhand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 10/16/2023 to 11/08/2023 for station 890: : 312it [00:29, 10.60it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 428760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bilasipara_Dhubri+Dhubri+Assam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 02/02/2023 to 02/20/2023 for station 864: : 51it [00:05,  9.83it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 72960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borbheta_Jorhat+Jorhat+Assam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 11/17/2023 to 12/05/2023 for station 886: : 339it [00:22, 15.20it/s]                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 282540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital_Electrical_Subdivision_Guwahati+Kamrup_Metro+Assam\n",
      "No valid data range for station 499, skipping...\n",
      "Chanho_Ranchi+Ranchi+Jharkhand\n",
      "Total entries: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/75 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chouparan_Hazaribagh+Hazaribagh+Jharkhand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 03/06/2023 to 03/17/2023 for station 904: : 76it [00:07, 10.05it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 108600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devpur-Dhule+Dhule+Maharashtra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 10/16/2023 to 10/21/2023 for station 302: : 294it [00:28, 10.31it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 353160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domadih_Godda+Godda+Jharkhand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 12/19/2023 to 12/26/2023 for station 889: : 360it [00:35, 10.22it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 496260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/262 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dudhimati_Koderma+Koderma+Jharkhand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 09/14/2023 to 09/20/2023 for station 906: : 263it [00:25, 10.19it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 378480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/210 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firozpur_Suratganj+Barabanki+Uttar_Pradesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 07/12/2023 to 07/30/2023 for station 741: : 211it [00:21, 10.02it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 303180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haider_Nagar_Palamu+Palamu+Jharkhand\n",
      "Total entries: 0\n",
      "Kairo_Loardaga+Loardaga+Jharkhand\n",
      "Total entries: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kapoorthala-Lucknow+Lucknow+Uttar_Pradesh\n",
      "No valid data range for station 704, skipping...\n",
      "Kardaitola_Nalbari+Nalbari+Assam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 12/19/2023 to 12/26/2023 for station 888: : 360it [00:36,  9.79it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 517800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khatarbari_Baksa+Baksa+Assam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 04/07/2023 to 04/14/2023 for station 910: : 104it [00:10, 10.02it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 146340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolebira_Simdega+Simdega+Jharkhand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 12/19/2023 to 12/26/2023 for station 873: : 360it [00:27, 13.07it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 369480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kothrud_Pune+Pune+Maharashtra\n",
      "No valid data range for station 875, skipping...\n",
      "Lalmatia_Godda+Godda+Jharkhand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 12/19/2023 to 12/26/2023 for station 902: : 360it [00:30, 11.83it/s]                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 429780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mahuadanr_Latehar+Latehar+Jharkhand\n",
      "Total entries: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/162 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malwada-Palghar+Palghar+Maharashtra\n",
      "Total entries: 0\n",
      "Mihijim_Jamatara+Jamatara+Jharkhand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 06/10/2023 to 06/12/2023 for station 899: : 163it [00:08, 18.58it/s]                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 96120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nagaon+Nagaon+Assam\n",
      "Total entries: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netarhat_Latehar+Latehar+Jharkhand\n",
      "Total entries: 0\n",
      "Nichinta_Goalpara+Goalpara+Assam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 06/10/2023 to 06/30/2023 for station 909: : 181it [00:21,  8.60it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 259860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paigwa-Barabanki+Barabanki+Uttar_Pradesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 02/02/2023 to 02/25/2023 for station 764: : 56it [00:03, 18.08it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 24360\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = retry_request(url=API_URL, session=session, headers=HEADERS)\n",
    "if res.ok:\n",
    "    text = res.text\n",
    "    text_list = text.split('<option value=\"\">-- Select  --</option>')[1].split('</select>')[0]\n",
    "    text_list = re.split('<option class=\"\" | >', text_list)\n",
    "    stationIDs = [elem[6:].replace('\\\"', '').replace(' ', '+') for elem in text_list if elem.startswith(\"value=\")]\n",
    "\n",
    "    last_scraped = {}\n",
    "    today_string = datetime.now().strftime('%m/%d/%Y')\n",
    "\n",
    "    if os.path.exists(INDIA_SCRAPE_DIR):\n",
    "        if os.path.exists(f'{INDIA_SCRAPE_DIR}/log.txt'):\n",
    "            with open(f'{INDIA_SCRAPE_DIR}/log.txt', 'r') as f:\n",
    "                print('Previous scraping log found:')\n",
    "                print(f'Last read: {f.readline().split(\":\")[1]}')\n",
    "                for line in f:\n",
    "                    title, id, date = line.strip().split(',')\n",
    "                    last_scraped[id] = (datetime.strptime(date, '%m/%d/%Y'), title)\n",
    "    else:\n",
    "        os.makedirs(INDIA_SCRAPE_DIR)\n",
    "\n",
    "    try:\n",
    "        for id in stationIDs:\n",
    "            url = f'http://www.watchyourpower.org/reports.php?location_id={id}'\n",
    "            res = retry_request(url=url, session=session, headers=HEADERS)\n",
    "\n",
    "            range_start = None\n",
    "            range_end = None\n",
    "            title = \"\"\n",
    "\n",
    "            if res:\n",
    "                empty_chart_match = re.search(r'<span class=\"empty_chart\">([\\S\\s]*?)<\\/span>', res.text)\n",
    "                if empty_chart_match:\n",
    "                    empty_chart_content = empty_chart_match.group(1)\n",
    "                    range_start = datetime.strptime(empty_chart_content.split('From ')[1].split(' To ')[0].strip(), '%d/%m/%Y')\n",
    "                    range_end = datetime.strptime(empty_chart_content.split(' To ')[1].strip(), '%d/%m/%Y')\n",
    "\n",
    "                    # Ensure range_start begins no earlier than January 1, 2023\n",
    "                    if range_start < datetime(year=2023, month=1, day=1):\n",
    "                        range_start = datetime(year=2023, month=1, day=1)\n",
    "                    # Ensure range_end does not exceed December 31, 2024\n",
    "                    if range_end > datetime(year=2024, month=12, day=31):\n",
    "                        range_end = datetime(year=2024, month=12, day=31)\n",
    "\n",
    "                title_match = re.search(r'<h4>[\\s]*?Location - (.*?), District - (.*?), State - (.*?) \\..*?<\\/h4>', res.text)\n",
    "                location = title_match.group(1).strip()\n",
    "                district = title_match.group(2).strip()\n",
    "                state = title_match.group(3).strip()\n",
    "                title = re.sub(r'[\\s]*-[\\s]*', '-', f'{location}+{district}+{state}'.replace('/', '_')).replace(' ', '_')\n",
    "                print(title)\n",
    "            else:\n",
    "                print(f'Failed to retrieve data for station {id}')\n",
    "                continue\n",
    "\n",
    "            # Ensure range_start and range_end are not None\n",
    "            if range_start is None or range_end is None:\n",
    "                print(f'No valid data range for station {id}, skipping...')\n",
    "                continue\n",
    "\n",
    "            # Query start and end dates\n",
    "            query_start = range_start\n",
    "            query_end = query_start + timedelta(days=31)\n",
    "\n",
    "            dates = []\n",
    "            voltages = []\n",
    "            with tqdm(total=(range_end - range_start).days) as pbar:\n",
    "                while query_end <= range_end and query_start < query_end:\n",
    "                    url = f'http://www.watchyourpower.org/reports.php?location_id={id}&from_date={date2query(query_start)}&to_date={date2query(query_end)}'\n",
    "                    res = retry_request(url=url, session=session, headers=HEADERS)\n",
    "\n",
    "                    if res:\n",
    "                        text = res.text\n",
    "                        pbar.set_description(f'Scraping {query_start.strftime(\"%m/%d/%Y\")} to {query_end.strftime(\"%m/%d/%Y\")} for station {id}')\n",
    "\n",
    "                        test_split = text.split('linechartData = [{')\n",
    "                        if len(test_split) < 2:\n",
    "                            pbar.set_description(f'No data found for station {id} between {query_start.strftime(\"%m/%d/%Y\")} and {query_end.strftime(\"%m/%d/%Y\")}')\n",
    "                            if not re.search(r'<span class=\"empty_chart\">([\\S\\s]*?)<\\/span>', res.text):\n",
    "                                with open(f'{INDIA_SCRAPE_DIR}/error_{id}_{query_start.strftime(\"%m-%d-%Y\")}.html', 'w') as f:\n",
    "                                    f.write(text)\n",
    "                        else:\n",
    "                            datapoints = test_split[1].split('];')[0].split('},{')\n",
    "                            for point in datapoints:\n",
    "                                date = datetime.strptime(point.split('\"date\":\"')[1].split('\",\"')[0], '%a %b %d %Y %H:%M:%S')\n",
    "                                voltage = int(point.split('\"voltage\":\"')[1].split('\"')[0])\n",
    "\n",
    "                                dates.append(date)\n",
    "                                voltages.append(voltage)\n",
    "\n",
    "                    pbar.update((query_end - query_start).days + 1)\n",
    "                    \n",
    "                    query_start = query_end + timedelta(days=1)\n",
    "                    query_end = query_start + timedelta(days=31)\n",
    "\n",
    "                    if query_end > range_end:\n",
    "                        query_end = range_end\n",
    "\n",
    "            last_scraped[id] = (range_end, title)\n",
    "\n",
    "            print(f'Total entries: {len(dates)}')\n",
    "            df = pd.DataFrame({'time': dates, 'voltage': voltages})\n",
    "\n",
    "            # Check if the file exists before trying to read the old data\n",
    "            csv_file_path = f'{INDIA_SCRAPE_DIR}/{id}+{title}.csv'\n",
    "            if os.path.exists(csv_file_path):\n",
    "                df_old = pd.read_csv(csv_file_path)\n",
    "                df = pd.concat([df_old, df], ignore_index=True)\n",
    "\n",
    "            # Save the dataframe to CSV\n",
    "            df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    finally:\n",
    "        with open(f'{INDIA_SCRAPE_DIR}/log.txt', 'w') as f:\n",
    "            f.write(f'Last Scraped:{today_string}\\n')\n",
    "            for id, info in last_scraped.items():\n",
    "                date = info[0]\n",
    "                title = info[1]\n",
    "                f.write(f'{title},{id},{date.strftime(\"%m/%d/%Y\")}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
