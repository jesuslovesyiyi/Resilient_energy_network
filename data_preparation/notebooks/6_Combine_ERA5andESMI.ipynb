{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_climate_data(input_dir):\n",
    "\tfolders = os.listdir(input_dir)\n",
    "\tdf_climate = pd.DataFrame()\n",
    "\n",
    "\tfor folder in folders:\n",
    "\t\tfiles = os.listdir(input_dir + '/' + folder)\n",
    "\n",
    "\t\tfor file in files:\n",
    "\t\t\tdf = pd.read_csv(input_dir + '/' + folder + '/' + file)\n",
    "\t\t\t# add station_id which is in the file name\n",
    "\t\t\tdf['station_id'] = file.split('_')[0]\n",
    "\t\t\tdf_climate = pd.concat([df_climate, df])\n",
    "\n",
    "\tdf_climate.drop(['From date', 'To date'], axis=1, inplace=True)\n",
    "\tdf_climate['date'] = df_climate['date'].astype(str)\n",
    "\tdf_climate['time'] = df_climate['time'].astype(str).apply(lambda x: x.zfill(4))\n",
    "\tdf_climate['datetime'] = pd.to_datetime(df_climate['date'] + df_climate['time'], format='%Y%m%d%H%M')\n",
    "\tdf_climate.set_index('datetime', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\tprint('Finished reading data...info below:')\n",
    "\tprint(df_climate.info())\n",
    "\n",
    "\tprint('index:', df_climate.index)\n",
    "\treturn df_climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_blackout_data(input_dir):\n",
    "\tfiles = os.listdir(input_dir)\n",
    "\tprint(files)\n",
    "\tdf_blackout = pd.DataFrame()\n",
    "\n",
    "\tfor file in files:\n",
    "\t\tdf = pd.read_csv(input_dir + '/' + file)\n",
    "\t\tdf['station_id'] = file.split('_')[-1].split('.')[0]\n",
    "\t\tdf_blackout = pd.concat([df_blackout, df])\n",
    "\n",
    "\tdf_blackout['hour'] = pd.to_datetime(\n",
    "\t\tdf_blackout['hour'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\tdf_blackout.set_index('hour', inplace=True)\n",
    "\tprint('Finished reading data...info below:')\n",
    "\tprint(df_blackout.info())\n",
    "\tprint('index:', df_blackout.index)\n",
    "\treturn df_blackout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading data...info below:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 13536 entries, 2013-11-15 10:00:00 to 2014-03-18 04:00:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       13536 non-null  int64  \n",
      " 1   Location name    13536 non-null  object \n",
      " 2   ESMI_ID          0 non-null      float64\n",
      " 3   District         13536 non-null  object \n",
      " 4   State            13536 non-null  object \n",
      " 5   Category         13536 non-null  object \n",
      " 6   Connection Type  13536 non-null  object \n",
      " 7   Lat              13536 non-null  float64\n",
      " 8   Lon              13536 non-null  float64\n",
      " 9   t2m              13536 non-null  float64\n",
      " 10  u10              13536 non-null  float64\n",
      " 11  v10              13536 non-null  float64\n",
      " 12  tp               13536 non-null  float64\n",
      " 13  date             13536 non-null  object \n",
      " 14  time             13536 non-null  object \n",
      " 15  station_id       13536 non-null  object \n",
      "dtypes: float64(7), int64(1), object(8)\n",
      "memory usage: 1.8+ MB\n",
      "None\n",
      "index: DatetimeIndex(['2013-11-15 10:00:00', '2013-12-09 02:00:00',\n",
      "               '2013-07-14 04:00:00', '2013-11-13 18:00:00',\n",
      "               '2013-09-14 03:00:00', '2013-07-10 14:00:00',\n",
      "               '2013-10-30 12:00:00', '2013-11-11 00:00:00',\n",
      "               '2013-08-09 09:00:00', '2013-11-17 08:00:00',\n",
      "               ...\n",
      "               '2014-06-26 23:00:00', '2014-11-27 18:00:00',\n",
      "               '2014-02-07 16:00:00', '2014-08-01 11:00:00',\n",
      "               '2014-04-25 23:00:00', '2014-01-25 04:00:00',\n",
      "               '2014-11-19 18:00:00', '2014-09-20 03:00:00',\n",
      "               '2014-06-18 23:00:00', '2014-03-18 04:00:00'],\n",
      "              dtype='datetime64[ns]', name='datetime', length=13536, freq=None)\n",
      "Index(['Unnamed: 0', 'Location name', 'ESMI_ID', 'District', 'State',\n",
      "       'Category', 'Connection Type', 'Lat', 'Lon', 't2m', 'u10', 'v10', 'tp',\n",
      "       'date', 'time', 'station_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_climate = read_climate_data('../../data/station_climate_by_year')\n",
    "\n",
    "# print columns\n",
    "print(df_climate.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hourly_station_217.csv', 'hourly_station_563.csv', 'hourly_station_445.csv']\n",
      "Finished reading data...info below:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 34200 entries, 2014-11-24 13:00:00 to 2018-10-01 08:00:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   pct_blackout  34200 non-null  float64\n",
      " 1   station_id    34200 non-null  object \n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 801.6+ KB\n",
      "None\n",
      "index: DatetimeIndex(['2014-11-24 13:00:00', '2014-11-24 14:00:00',\n",
      "               '2014-11-24 15:00:00', '2014-11-24 16:00:00',\n",
      "               '2014-11-24 17:00:00', '2014-11-24 18:00:00',\n",
      "               '2014-11-24 19:00:00', '2014-11-24 20:00:00',\n",
      "               '2014-11-24 21:00:00', '2014-11-24 22:00:00',\n",
      "               ...\n",
      "               '2018-08-22 22:00:00', '2018-08-22 23:00:00',\n",
      "               '2018-08-23 00:00:00', '2018-08-23 01:00:00',\n",
      "               '2018-08-23 02:00:00', '2018-08-23 03:00:00',\n",
      "               '2018-08-23 04:00:00', '2018-08-23 05:00:00',\n",
      "               '2018-08-23 06:00:00', '2018-10-01 08:00:00'],\n",
      "              dtype='datetime64[ns]', name='hour', length=34200, freq=None)\n",
      "columns: Index(['pct_blackout', 'station_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_blackout = read_blackout_data('../../data/india_hourly')\n",
    "\n",
    "# print(df_blackout['station_id'].unique())\n",
    "# print columns name\n",
    "print('columns:',df_blackout.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2013-11-15 10:00:00', '2013-12-09 02:00:00',\n",
      "               '2013-07-14 04:00:00', '2013-11-13 18:00:00',\n",
      "               '2013-09-14 03:00:00', '2013-07-10 14:00:00',\n",
      "               '2013-10-30 12:00:00', '2013-11-11 00:00:00',\n",
      "               '2013-08-09 09:00:00', '2013-11-17 08:00:00',\n",
      "               ...\n",
      "               '2014-06-26 23:00:00', '2014-11-27 18:00:00',\n",
      "               '2014-02-07 16:00:00', '2014-08-01 11:00:00',\n",
      "               '2014-04-25 23:00:00', '2014-01-25 04:00:00',\n",
      "               '2014-11-19 18:00:00', '2014-09-20 03:00:00',\n",
      "               '2014-06-18 23:00:00', '2014-03-18 04:00:00'],\n",
      "              dtype='datetime64[ns]', name='datetime', length=13536, freq=None)\n",
      "DatetimeIndex(['2014-11-24 13:00:00', '2014-11-24 14:00:00',\n",
      "               '2014-11-24 15:00:00', '2014-11-24 16:00:00',\n",
      "               '2014-11-24 17:00:00', '2014-11-24 18:00:00',\n",
      "               '2014-11-24 19:00:00', '2014-11-24 20:00:00',\n",
      "               '2014-11-24 21:00:00', '2014-11-24 22:00:00',\n",
      "               ...\n",
      "               '2018-08-22 22:00:00', '2018-08-22 23:00:00',\n",
      "               '2018-08-23 00:00:00', '2018-08-23 01:00:00',\n",
      "               '2018-08-23 02:00:00', '2018-08-23 03:00:00',\n",
      "               '2018-08-23 04:00:00', '2018-08-23 05:00:00',\n",
      "               '2018-08-23 06:00:00', '2018-10-01 08:00:00'],\n",
      "              dtype='datetime64[ns]', name='hour', length=34200, freq=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_climate.index)\n",
    "print(df_blackout.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Location name', 'ESMI_ID', 'District', 'State',\n",
      "       'Category', 'Connection Type', 'Lat', 'Lon', 't2m', 'u10', 'v10', 'tp',\n",
      "       'date', 'time', 'station_id_climate', 'pct_blackout',\n",
      "       'station_id_blackout'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# merge df_climate, df_blackout with datetime and station_id: \n",
    "# in df_climate, the merge index is datetime and station_id\n",
    "# in df_blackout, index is hour and station_id\n",
    "\n",
    "df = pd.merge(df_climate, df_blackout, left_index=True, right_index=True, how='inner', suffixes=('_climate', '_blackout'))\n",
    "\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 655 entries, 2014-11-24 13:00:00 to 2014-12-31 23:00:00\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           655 non-null    int64  \n",
      " 1   Location name        655 non-null    object \n",
      " 2   ESMI_ID              0 non-null      float64\n",
      " 3   District             655 non-null    object \n",
      " 4   State                655 non-null    object \n",
      " 5   Category             655 non-null    object \n",
      " 6   Connection Type      655 non-null    object \n",
      " 7   Lat                  655 non-null    float64\n",
      " 8   Lon                  655 non-null    float64\n",
      " 9   t2m                  655 non-null    float64\n",
      " 10  u10                  655 non-null    float64\n",
      " 11  v10                  655 non-null    float64\n",
      " 12  tp                   655 non-null    float64\n",
      " 13  date                 655 non-null    object \n",
      " 14  time                 655 non-null    object \n",
      " 15  station_id_climate   655 non-null    object \n",
      " 16  pct_blackout         655 non-null    float64\n",
      " 17  station_id_blackout  655 non-null    object \n",
      "dtypes: float64(8), int64(1), object(9)\n",
      "memory usage: 97.2+ KB\n",
      "None\n",
      "                     Unnamed: 0  Location name  ESMI_ID District  \\\n",
      "2014-11-24 13:00:00        6327  Sikandarabad       NaN  Sitapur   \n",
      "2014-11-24 14:00:00        4457  Sikandarabad       NaN  Sitapur   \n",
      "2014-11-24 15:00:00        3873  Sikandarabad       NaN  Sitapur   \n",
      "2014-11-24 16:00:00        3163  Sikandarabad       NaN  Sitapur   \n",
      "2014-11-24 17:00:00        6043  Sikandarabad       NaN  Sitapur   \n",
      "\n",
      "                             State        Category Connection Type        Lat  \\\n",
      "2014-11-24 13:00:00  Uttar Pradesh  Gram Panchayat        Domestic  27.954139   \n",
      "2014-11-24 14:00:00  Uttar Pradesh  Gram Panchayat        Domestic  27.954139   \n",
      "2014-11-24 15:00:00  Uttar Pradesh  Gram Panchayat        Domestic  27.954139   \n",
      "2014-11-24 16:00:00  Uttar Pradesh  Gram Panchayat        Domestic  27.954139   \n",
      "2014-11-24 17:00:00  Uttar Pradesh  Gram Panchayat        Domestic  27.954139   \n",
      "\n",
      "                           Lon        t2m       u10       v10            tp  \\\n",
      "2014-11-24 13:00:00  80.491162  292.49493  2.014306 -1.304936  8.553265e-07   \n",
      "2014-11-24 14:00:00  80.491162  290.62530  1.939066 -1.267732  8.553265e-07   \n",
      "2014-11-24 15:00:00  80.491162  289.07650  1.993549 -1.040938  8.553265e-07   \n",
      "2014-11-24 16:00:00  80.491162  287.76422  2.078859 -0.714382  1.722779e-06   \n",
      "2014-11-24 17:00:00  80.491162  286.74090  2.225251 -0.380365  1.710557e-06   \n",
      "\n",
      "                         date  time station_id_climate  pct_blackout  \\\n",
      "2014-11-24 13:00:00  20141124  1300            station      0.000000   \n",
      "2014-11-24 14:00:00  20141124  1400            station      0.000000   \n",
      "2014-11-24 15:00:00  20141124  1500            station      0.066667   \n",
      "2014-11-24 16:00:00  20141124  1600            station      0.066667   \n",
      "2014-11-24 17:00:00  20141124  1700            station      0.016667   \n",
      "\n",
      "                    station_id_blackout  \n",
      "2014-11-24 13:00:00                 217  \n",
      "2014-11-24 14:00:00                 217  \n",
      "2014-11-24 15:00:00                 217  \n",
      "2014-11-24 16:00:00                 217  \n",
      "2014-11-24 17:00:00                 217  \n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv('../../data/merged_data.csv')\n",
    "\n",
    "# fix: id seems not the same, need to check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2m           292.49493\n",
      "u10            2.014306\n",
      "v10           -1.304936\n",
      "station_id          217\n",
      "Name: 2014-11-24 13:00:00, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# select the t2m, u10, v10, and station_id for datetime 2014-11-24 13:00:00, station Sikandarabad\n",
    "\n",
    "print(df.loc['2014-11-24 13:00:00', ['t2m', 'u10', 'v10', 'station_id']])\n",
    "\n",
    "# select the t2m, u10, v10, and station_id for datetime 2014-11-24 13:00:00, station Sikandarabad\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
